{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念补充\n",
    "### 信息增益\n",
    "信息熵（entropy）是度量样本集合“纯度”最常用的一种指标，假定当前样本集合$D$中$k$类样本所占比例为$p_k$,      \n",
    "则D的信息熵定义为$Ent(D)=-\\sum\\limits_{k=1}^{|y|}p_klog_2 {p_k}$      \n",
    "> 计算时规定$p=0$时，$Ent(D)=0$     \n",
    "$Ent(D)$最小值为0，最大值为$log_2|y|$       \n",
    "\n",
    "信息增益直接以信息熵为基础，计算当前划分对信息熵所造成的变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树基本概念\n",
    "![image](images/jcs.png)      \n",
    "\n",
    "**树的含义**     \n",
    "- 每个内部结点对应于某个属性上的测试\n",
    "- 每个分支对应于测试的一种可能性\n",
    "- 每个叶结点对应一种预测结果   \n",
    "\n",
    "**学习过程：**对训练样本分析来“划分属性”（即内部结点对应的属性）     \n",
    "**预测过程：**将测试示例从根结点开始，沿着划分属性所构成的“判定测试序列”下行，直到叶结点   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树简史  \n",
    "- **第一个决策树算法: CLS(Concept Learning System)**   \n",
    "[E B. Hunt, J. Marin, and P. T. Stone's book \"Experiments in\n",
    "Induction published by Academic Press in 1966 \n",
    "- **主流算法：ID3**    \n",
    "J.R. Quinlan's paper in a book \"Expert Systems in the micro\n",
    "Electronic Age edited by D. Michie, published by edinburgh\n",
    "University press in 1979   \n",
    "- **最常用：C4.5**    \n",
    "J.R. Quinlan's book\"C4.5: Programs\n",
    "for Machine Learning\" published by\n",
    "Morgan Kaufmann in 1993      \n",
    "- **可以用于回归任务的决策树算法:CART( Classification and\n",
    "Regression tree)**    \n",
    "[L Breiman, J H. Friedman, R A Olshen, and C J. Stone's book\n",
    "Classification and Regression Trees published by Wadsworth\n",
    "in1984\n",
    "- **基于决策树的最强大算法:RF( Random forest)**       \n",
    "[L. Breiman's MLJ'01 paper Random Forest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本流程\n",
    "\n",
    "策略:“分而治之”( divide-and-conquer)\n",
    "自根至叶的递归过程\n",
    "在每个中间结点寻找一个“划分”( split or test)属性\n",
    "\n",
    "**3种停止条件:**\n",
    "- (1)当前结点包含的样本全属于同一类别,无需划分;\n",
    "- (2)当前属性集为空,或是所有样本在所有属性上取值相同,无法划分;\n",
    "- (3)当前结点包含的样本集合为空,不能划分.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同决策树算法的基本原理\n",
    "### ID3算法\n",
    "离散属性$a$的取值为$\\{a_1,a_2.\\cdots,a_V\\}$      \n",
    "$D_v:D$中在$a$上取值$=a_v$的样本集合      \n",
    "以属性$a$对数据集$D$进行划分所获得的信息增益为     \n",
    "$Gain(D,a)=Ent(D)-\\sum\\limits_{v=1}^V\\frac{|D_v|}{|D|}Ent(D_v)$      \n",
    "其中前一项是划分前的信息熵，后一项是划分后的信息熵，$\\frac{|D_v|}{|D|}$代表了第$v$个分支的权重，样本越多越重要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**从文件中导入数据**    \n",
    "\n",
    "- 文件的第一行为属性，剩余行为各属性值\n",
    "- 文件类型为csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['编号' '色泽' '根蒂' '敲声' '纹理' '脐部' '触感' '密度' '含糖率' '好瓜']\n",
      "[['1' '青绿' '蜷缩' '浊响' '清晰' '凹陷' '硬滑' '0.697' '0.46' '是']\n",
      " ['2' '乌黑' '蜷缩' '沉闷' '清晰' '凹陷' '硬滑' '0.774' '0.376' '是']\n",
      " ['3' '乌黑' '蜷缩' '浊响' '清晰' '凹陷' '硬滑' '0.634' '0.264' '是']\n",
      " ['4' '青绿' '蜷缩' '沉闷' '清晰' '凹陷' '硬滑' '0.608' '0.318' '是']\n",
      " ['5' '浅白' '蜷缩' '浊响' '清晰' '凹陷' '硬滑' '0.556' '0.215' '是']\n",
      " ['6' '青绿' '稍蜷' '浊响' '清晰' '稍凹' '软粘' '0.403' '0.237' '是']\n",
      " ['7' '乌黑' '稍蜷' '浊响' '稍糊' '稍凹' '软粘' '0.481' '0.149' '是']\n",
      " ['8' '乌黑' '稍蜷' '浊响' '清晰' '稍凹' '硬滑' '0.437' '0.211' '是']\n",
      " ['9' '乌黑' '稍蜷' '沉闷' '稍糊' '稍凹' '硬滑' '0.666' '0.091' '否']\n",
      " ['10' '青绿' '硬挺' '清脆' '清晰' '平坦' '软粘' '0.243' '0.267' '否']\n",
      " ['11' '浅白' '硬挺' '清脆' '模糊' '平坦' '硬滑' '0.245' '0.057' '否']\n",
      " ['12' '浅白' '蜷缩' '浊响' '模糊' '平坦' '软粘' '0.343' '0.099' '否']\n",
      " ['13' '青绿' '稍蜷' '浊响' '稍糊' '凹陷' '硬滑' '0.639' '0.161' '否']\n",
      " ['14' '浅白' '稍蜷' '沉闷' '稍糊' '凹陷' '硬滑' '0.657' '0.198' '否']\n",
      " ['15' '乌黑' '稍蜷' '浊响' '清晰' '稍凹' '软粘' '0.36' '0.37' '否']\n",
      " ['16' '浅白' '蜷缩' '浊响' '模糊' '平坦' '硬滑' '0.593' '0.042' '否']\n",
      " ['17' '青绿' '蜷缩' '沉闷' '稍糊' '稍凹' '硬滑' '0.719' '0.103' '否']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "@description:载入数据\n",
    "@params:input_file-文件名；delimiter-分隔符\n",
    "@return:dataSet-二维数组，每一行代表一个样本，每一列代表一个属性；attr-所有属性值\n",
    "\"\"\"\n",
    "def loadDataSet(input_file,delimiter):\n",
    "    dataSet = []\n",
    "    attr = []\n",
    "    with open(input_file,\"r\",encoding='utf-8') as f:\n",
    "        head = f.readline().strip()\n",
    "        attr = head.split(delimiter)\n",
    "        for line in f:\n",
    "            values = line.strip().split(delimiter)\n",
    "            dataSet.append(values)\n",
    "    return np.array(dataSet),np.array(attr)\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "input_file = \"files/xigua_data3.0.csv\"\n",
    "dataSet,labels = loadDataSet(input_file,\",\")\n",
    "print(labels)\n",
    "print(dataSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 计算数据集D中有几种类\n",
    "def count_type(D):\n",
    "    type_list = D[:,-1]\n",
    "    return len(set(type_list))\n",
    "\n",
    "# 测试代码\n",
    "D = np.array([[1,2,3],[1,2,4],[2,3,4]])\n",
    "print(count_type(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 计算数据集D中数据在A中所有属性上取值的最大值\n",
    "def count_attr(D,A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'是'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def more_typeNum(D):\n",
    "    dictory = {}\n",
    "    type_list = D[:,-1]\n",
    "    for i in type_list:\n",
    "        if i not in dictory.keys():\n",
    "            dictory[i] = 0\n",
    "        dictory[i] += 1\n",
    "        \n",
    "    max_num = -1\n",
    "    max_type = \"\"\n",
    "    for item in dictory.items():\n",
    "        if item[1] > max_num:\n",
    "            max_num = item[1]\n",
    "            max_type = item[0]\n",
    "    return max_type\n",
    "\n",
    "D = np.array([['青绿','蜷缩','浊响','是']\n",
    " ,['乌黑','蜷缩','沉闷','是']\n",
    " ,['乌黑','蜷缩','浊响','否']])\n",
    "more_typeNum(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6365141682948128\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\"\"\"\n",
    "计算给定数据集的信息熵（香农熵）\n",
    "@ param dataSet:数据集\n",
    "@ return shannonEnt:香农熵\n",
    "\"\"\"\n",
    "def calcShannonEnt(dataSet,attr):\n",
    "    # 根据attr的取值将dataSet分类\n",
    "    label_list = dataSet[:,attr]\n",
    "    label_set = list(set(label_list))\n",
    "    count = {}\n",
    "    cnt = 0\n",
    "    for row in dataSet:\n",
    "        if row[attr] not in count.keys():\n",
    "            count[row[attr]] = 0\n",
    "        count[row[attr]] += 1\n",
    "        cnt += 1\n",
    "    \n",
    "    sumNum = 0\n",
    "    for key in count.keys():\n",
    "        pk = count[key]/cnt\n",
    "        sumNum -= pk*math.log(pk)\n",
    "    print(sumNum)\n",
    "        \n",
    "# 测试\n",
    "D = np.array([['青绿','蜷缩','浊响','是']\n",
    " ,['乌黑','蜷缩','沉闷','是']\n",
    " ,['乌黑','蜷缩','浊响','否']])\n",
    "attr = len(D[0])-1\n",
    "calcShannonEnt(D,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 从属性A中找到最优属性\n",
    "def findBest(D,A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 将单属性a的值为value的数据提取出来\n",
    "def extract_by_attr(D,a,value):\n",
    "    extract_D = []\n",
    "    for row in D:\n",
    "        if D[row,a]==value:\n",
    "            extract_D.append(row)\n",
    "    return extract_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'稍蜷', '蜷缩'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 计算D数据集中a*的取值范围\n",
    "def uniqueValues(D,a_star):\n",
    "    return np.array(set(D[:,a_star]))\n",
    "\n",
    "# 测试\n",
    "D = np.array([['乌黑','稍蜷','浊响'],\n",
    "    ['浅白','稍蜷','浊响'],\n",
    "    ['乌黑','蜷缩','浊响']])\n",
    "print(uniqueValues(D,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**树的结构**用一个**字典**来表示   \n",
    "如：   \n",
    "root = {\"色泽\":{\"青绿\":根蒂,\"乌黑\":根蒂,\"浅白\":\"好瓜\"}}     \n",
    "根蒂 = {\"根蒂\":{\"蜷缩\":蜷缩,\"硬挺\":\"好瓜\"}}，即根蒂为一个子树    \n",
    "\n",
    "**算法的三个终止条件**    \n",
    "- (1)当前结点包含的样本全属于同一类别,无需划分;\n",
    "- (2)当前属性集为空,或是所有样本在所有属性上取值相同,无法划分;\n",
    "- (3)当前结点包含的样本集合为空,不能划分."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D:Training Set，二维数组；A:Attribute，一维数组；label:原始属性对应关系\n",
    "def treeGenerate(D,A,label):\n",
    "    # （1）若D中样本全属于同一类别C,将新节点标记为C\n",
    "    if count_type(D) == 1:\n",
    "        return D[0,-1]\n",
    "\n",
    "    # （2）若A为空集 OR D中样本在A上取值相同\n",
    "    elif len(A)==0 or count_attr(D,A)==1:\n",
    "        # 将类别标记为D中样本数量最多的点\n",
    "        return  more_typeNum(D)\n",
    "    \n",
    "    # （3）否则，选取最优属性进行划分\n",
    "    else:\n",
    "        # 从A中选取最优属性a*\n",
    "        a_star = findBest(D,A)\n",
    "        \n",
    "        aValues = uniqueValues(D,a_star) # D数据集中a*的取值范围\n",
    "        for value in  aValues:\n",
    "            tree = {label[a_star]:{}} # 生成一个新的分支\n",
    "            Dv = extract_by_attr(D,a_star,value)\n",
    "            if not Dv:\n",
    "                tree[label[a_star]] = more_typeNum(D)\n",
    "            else:\n",
    "                A.del(a_star)\n",
    "                tree[label[a_star]] = treeGenerate(Dv,A,label)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree:决策树;labels:属性\n",
    "def predict(tree,labels):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def main():\n",
    "    # 读取Training Set和Attribute\n",
    "    input_file = \"files/xigua_data3.0.csv\"\n",
    "    trainingSet,attribute = loadDataSet(input_file,\",\")\n",
    "    \n",
    "    # 将字符串类型的attribute转换成数字\n",
    "    A = np.arange(len(attribute)) \n",
    "    # 生成决策树\n",
    "    decision_tree = treeGenerate(trainingSet,A)\n",
    "    # 原始信息增益\n",
    "    EntD = calcShannonEnt(trainingSet)\n",
    "    \n",
    "    # 根据决策树进行预测\n",
    "    # (1) 用户输入瓜的属性信息\n",
    "    print(\"please input the \",attribute)\n",
    "    \n",
    "    # (2) 预测\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
