{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习系统中主要的组成部分是数据处理流水线。     \n",
    "在数据被输入到机器学习算法中进行训练之前，需要对数据做各种方式的处理，使得该数据可以被算法利用。\n",
    "在构建一个准确的、可扩展的机器学习系统中，拥有一个健壮的数据处理流水线非常重要。\n",
    "有很多基本的函数可以使用，通常数据处理流水线就是这些函数的组合。     \n",
    "不推荐用嵌套或循环的方式调用这些函数，而是用函数式编程的方式构建函数组合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Operation: sub5(mul2(add3(arr)))\n",
      "Output using the lengthy way: [5, 11, 9, 15]\n",
      "Output using function composition: [5, 11, 9, 15]\n",
      "\n",
      "Operation: mul2(sub5(mul2(add3(sub5(arr)))))\n",
      "Output: [-10, 2, -2, 10]\n"
     ]
    }
   ],
   "source": [
    "# 函数组合\n",
    "import numpy as np\n",
    "from functools import reduce \n",
    "\n",
    "def add3(input_array):\n",
    "    return map(lambda x: x+3, input_array)\n",
    "\n",
    "def mul2(input_array):\n",
    "    return map(lambda x: x*2, input_array)\n",
    "\n",
    "def sub5(input_array):\n",
    "    return map(lambda x: x-5, input_array)\n",
    "\n",
    "def function_composer(*args):\n",
    "    return reduce(lambda f, g: lambda x: f(g(x)), args)\n",
    "#     函数将一个数据集合（链表，元组等）中的所有数据进行下列操作：\n",
    "#     用传给 reduce 中的函数 function（有两个参数）先对集合中的第 1、2 个元素进行操作，\n",
    "#     得到的结果再与第三个数据用 function 函数运算，最后得到一个结果\n",
    "\n",
    "\n",
    "def test():\n",
    "    arr = np.array([2,5,4,7])\n",
    "\n",
    "    print(\"\\nOperation: sub5(mul2(add3(arr)))\")\n",
    "    \n",
    "    arr1 = add3(arr)\n",
    "    arr2 = mul2(arr1)\n",
    "    arr3 = sub5(arr2)\n",
    "    print(\"Output using the lengthy way:\", list(arr3))\n",
    "\n",
    "    func_composed = function_composer(sub5, mul2, add3)\n",
    "    print(\"Output using function composition:\", list(func_composed(arr)))\n",
    "\n",
    "    print(\"\\nOperation: mul2(sub5(mul2(add3(sub5(arr)))))\\nOutput:\", \\\n",
    "            list(function_composer(mul2, sub5, mul2, add3, sub5)(arr)))\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**机器学习流水线工作原理**   \n",
    "- 选择k个最佳特征的方式是基于单变量的特征选择\n",
    "- 选择过程是先进行变量统计测试，然后从特征向量中抽取最优秀的特征\n",
    "- 做了这些测试后，向量空间的每个特征将有一个评价分数。基于这些评价分数，选择最好的k个特征\n",
    "- 一旦抽取出k个特征，一个k维特征向量就形成了，可以将这个特征向量用于随机森林分类器的输入训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      " [1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1]\n",
      "\n",
      "Score: 0.97\n",
      "\n",
      "Selected features (0-indexed): 0, 5, 9, 10, 11, 15\n"
     ]
    }
   ],
   "source": [
    "# 机器学习流水线\n",
    "# 包括预处理、特征选择、监督学习、非监督学习等函数\n",
    "from sklearn.datasets import samples_generator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 生成一些示例数据\n",
    "X, y = samples_generator.make_classification(\n",
    "        n_informative=4, n_features=20, n_redundant=0, random_state=5)\n",
    "# n_features :特征个数，n_informative：多信息特征的个数，n_redundant：冗余信息，informative特征的随机线性组合\n",
    "\n",
    "# 特征选择器\n",
    "selector_k_best = SelectKBest(f_regression, k=10)\n",
    "# 随机森林分类器\n",
    "classifier = RandomForestClassifier(n_estimators=50, max_depth=4)\n",
    "# 构建机器学习流水线\n",
    "pipeline_classifier = Pipeline([('selector', selector_k_best), ('rf', classifier)])\n",
    "# 可以选择更新这些参数\n",
    "pipeline_classifier.set_params(selector__k=6, \n",
    "        rf__n_estimators=25)\n",
    "# 训练分类器\n",
    "pipeline_classifier.fit(X, y)\n",
    "# 预测输出结果\n",
    "prediction = pipeline_classifier.predict(X)\n",
    "print(\"\\nPredictions:\\n\", prediction)\n",
    "# 打印分类器得分\n",
    "print(\"\\nScore:\", pipeline_classifier.score(X, y))\n",
    "\n",
    "# 打印被分类器选中的特征\n",
    "features_status = pipeline_classifier.named_steps['selector'].get_support()\n",
    "selected_features = []\n",
    "for count, item in enumerate(features_status):\n",
    "    if item:\n",
    "        selected_features.append(count)\n",
    "\n",
    "print(\"\\nSelected features (0-indexed):\", ', '.join([str(x) for x in selected_features]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
